{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaf6aae-696b-46fc-bf07-b9f80b8208fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### U Net 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18f380",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rasterio as rio \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from rasterio.features import rasterize\n",
    "from osgeo import gdal\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import NearestNDInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import gc\n",
    "from torch.utils.data import DataLoader, random_split, RandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn, optim\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9102a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b86bf-b8dc-4723-8f69-022c94536005",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940be772-a271-4417-8127-c1b2014cc3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when there is one dataset \n",
    "\n",
    "# dataset=pd.read_csv(\"path/Dataset\")\n",
    "\n",
    "# when there are two datasets to analyze\n",
    "\n",
    "# dataset1=pd.read_csv(\"path/Dataset1/Dataset128\")\n",
    "# dataset2=pd.read_csv(\"path/Dataset2/Dataset128\")  \n",
    "# dataset=pd.concat([dataset1,dataset2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04899a-0a07-45f8-b3eb-70b99fdd7a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(imgdata):\n",
    "    \"\"\"\n",
    "    Preprocesses each image's data, removing outliers and values out of range. \n",
    "\n",
    "    imgdata (object: ndarray): Matrix composed of the 16 concatenated matrices of a pre and post-fire image' bands\n",
    "\n",
    "    \"\"\"\n",
    "    #the limits are determined according to the Dataset's nature\n",
    "    LS_max=[3660.5,  4303.5,  4832.0,  6956.0,  6174.5,  6234.0, 1,  1000,  3811.0,  4504.0,  4950.5,\n",
    "    7000.5,  6210.0,  6286.5, 1,  1000]\n",
    "    LI_min= [0.0,  0.0,  0.0,  0.0,  0.0,  0.0,  -0.6903,  -605.3293, 0.0,  0.0,  0.0,  0.0,  0.0,\n",
    "    0.0,  -0.7970,  -573.0518]\n",
    "    mean_sprepro=[415.8392, 646.4156, 761.339, 2109.5385, 1843.5207, 1189.6269, 0.4677, 301.9405,\n",
    "    414.9891, 657.8648, 761.992, 2235.3473, 1853.7414, 1160.7475, 0.4924, 341.9075]\n",
    "    for k in range(1,17):\n",
    "        if (imgdata[k-1]>LS_max[k-1]).any():\n",
    "            if imgdata[k-1].mean()<LS_max[k-1]:\n",
    "                imgdata[k-1][imgdata[k-1]>LS_max[k-1]]=imgdata[k-1].mean()\n",
    "            else:\n",
    "                imgdata[k-1][imgdata[k-1]>LS_max[k-1]]=mean_sprepro[k-1]\n",
    "        elif (imgdata[k-1]<LI_min[k-1]).any():\n",
    "            if imgdata[k-1].mean()>LI_min[k-1]:\n",
    "                imgdata[k-1][imgdata[k-1]<LI_min[k-1]]=imgdata[k-1].mean()\n",
    "            else: \n",
    "                imgdata[k-1][imgdata[k-1]<LI_min[k-1]]=mean_sprepro[k-1]\n",
    "    return imgdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b504663-6e8d-4ff0-bcdd-41c864fd47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class firescardataset():\n",
    "    def __init__(self, dataset, subset_size1, subset_size2_, subset_size3, subset_size4, mult=1, transform=None):\n",
    "        \"\"\"\n",
    "        Processes the data to enter into the net. The data to enter can be selected indicating the subset_size(x), dividing the first two \n",
    "        for the data of one region, while the latter two for the one of the other region.\n",
    "        The files' paths must be defined for the pre- and post-fire images and firescars files. \n",
    "\n",
    "        dataset (Object):  Pandas dataframe with the data's filenames from two different regions. There are 3 columns with the required data filenames for \n",
    "        each input. \"ImPosF\": The image post Fire, \"ImgPreF\": The image pre Fire, and \"FireScar_tif\": The label, in a raster file\n",
    "        subset_size1 (int): index of the first input from the Dataset 1: Region of Valparaiso\n",
    "        subset_size2 (int): index of the last input from the Dataset 1: Region of Valparaiso\n",
    "        subset_size3 (int): index of the first input from the Dataset 2: Region of Biobio\n",
    "        subset_size4 (int): index of the last input from the Dataset 2: Region of Biobio\n",
    "        mult (int): times to input the data\n",
    "        transform: in case there is an aditional transformation to apply to the data, it must be given\n",
    "    \n",
    "        \"\"\"        \n",
    "        self.transform = transform\n",
    "        # list of image files (pre and post fire), and labels\n",
    "        # label vector edge coordinates\n",
    "        self.imgfiles = []\n",
    "        self.imgprefiles=[]\n",
    "        self.labels = []\n",
    "        self.seglabels = []\n",
    "        imgposfiles = []\n",
    "        # read in segmentation label files\n",
    "        for i in range(subset_size1,subset_size2):\n",
    "            segdata = os.path.join(\"path/to/Firescars/Dataset1/\", dataset.loc[i,\"FireScar_tif\"])\n",
    "            self.seglabels.append(segdata)\n",
    "            self.imgfiles.append(os.path.join(\"path/to/Img/Post/Dataset1/\",dataset.loc[i,\"ImgPosF\"]))\n",
    "            self.imgprefiles.append(os.path.join(\"path/to/Img/Pre/Dataset1/\",dataset.loc[i,\"ImgPreF\"]))\n",
    "        for i in range(subset_size3,subset_size4):\n",
    "            self.seglabels.append(os.path.join(\"path/to/Firescars/Dataset2/\",dataset.loc[i,\"FireScar_tif\"]))\n",
    "            self.imgfiles.append(os.path.join(\"path/to/Img/Post/Dataset2/\",dataset.loc[i,\"ImgPosF\"]))\n",
    "            self.imgprefiles.append(os.path.join(\"path/to/Img/Pre/Dataset2/\",dataset.loc[i,\"ImgPreF\"]))\n",
    "        self.imgfiles = np.array(self.imgfiles)\n",
    "        self.imgprefiles=np.array(self.imgprefiles)\n",
    "        self.labels = np.array(self.labels)\n",
    "        \n",
    "        if mult > 1:\n",
    "            self.imgfiles = np.array([*self.imgfiles] * mult)\n",
    "            self.imgprefiles = np.array([*self.imgprefiles] * mult)\n",
    "            self.labels = np.array([*self.labels] * mult)\n",
    "            self.seglabels = self.seglabels * mult\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgfiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Accesses to the input's data and adapts the format to a matrix of the concatenated bands' values of both the pre and post-fire images. \n",
    "        Afterwards, also padding and preprocessing are applied to the data. \n",
    "        Returns a dictionary of the image's data and the values.\n",
    "\n",
    "        idx (int): index of the input to access to. They are given iteratively for a given search.\n",
    "        \n",
    "        \"\"\"\n",
    "        idx=idx-1\n",
    "        imgfile = rio.open(self.imgfiles[idx])\n",
    "        imgpre=rio.open(self.imgprefiles[idx])\n",
    "        imgdata1 = np.array([imgfile.read(i) for i in [1,2,3,4,5,6,7,8]])\n",
    "        imgdatapre=np.array([imgpre.read(i) for i in [1,2,3,4,5,6,7,8]])\n",
    "        imgdata=np.concatenate((imgdata1, imgdatapre), axis=0)\n",
    "        imgdata[imgdata==0]=np.nan\n",
    "\n",
    "        if (np.isfinite(imgdata)==False).any():                      #Replace nan for the neighbours mean values\n",
    "            mask=np.where(np.isfinite(imgdata))\n",
    "            interp=NearestNDInterpolator(np.transpose(mask), imgdata[mask])\n",
    "            imgdata=interp(*np.indices(imgdata.shape))\n",
    "\n",
    "        ds = gdal.Open(self.seglabels[idx])\n",
    "        myarray = np.array(ds.GetRasterBand(1).ReadAsArray())\n",
    "\n",
    "        x=imgdata1.shape[1]\n",
    "        y=imgdata1.shape[2]\n",
    "\n",
    "      #FireScar padding to 128 in case is not that size\n",
    "        x,y=myarray.shape\n",
    "                                                                    #only to equalize to 128x128 images or it could be to image size \n",
    "        ulx_i, lry_i, lrx_i, uly_i=imgfile.bounds\n",
    "        ulx, xres, xskew, uly, yskew, yres  = ds.GetGeoTransform()\n",
    "        lrx = ulx + (ds.RasterXSize * xres)\n",
    "        lry = uly + (ds.RasterYSize * yres)\n",
    "        left=round((ulx-ulx_i)/xres)    #np.pad(a, up, down, left, right)\n",
    "        right=round((lrx_i-lrx)/xres)\n",
    "        up=round((uly-uly_i)/yres)\n",
    "        down=round((lry_i-lry)/yres)\n",
    "        myarray=np.pad(myarray,((up, down),(left,right)),\"constant\")\n",
    "\n",
    "        imgdata=preprocessing(imgdata)                               #preprocessing to the data when there are values off range (i.e outliers)\n",
    "\n",
    "        sample = {'idx': idx,\n",
    "              'img': imgdata,\n",
    "              'fpt': myarray,\n",
    "              'imgfile': self.imgfiles[idx]}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Returns converted Tensor sample\n",
    "        \n",
    "        sample: sample to be converted to Tensor\n",
    "        \n",
    "        \"\"\"\n",
    "        out = {'idx': sample['idx'],\n",
    "        'img': torch.from_numpy(sample['img'].copy()),\n",
    "        'fpt': torch.from_numpy(sample['fpt'].copy()),\n",
    "        'imgfile': sample['imgfile']}\n",
    "\n",
    "        return out\n",
    "class Randomize(object):\n",
    "    \"\"\"Randomize image orientation including rotations by integer multiples of\n",
    "    90 deg, (horizontal) mirroring, and (vertical) flipping.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Randomizes the sample\n",
    "        \n",
    "        sample: sample to be randomized\n",
    "        \n",
    "        \"\"\"\n",
    "        imgdata = sample['img']\n",
    "        fptdata = sample['fpt']\n",
    "        idx=sample[\"idx\"]\n",
    "        # mirror horizontally\n",
    "        mirror = np.random.randint(0, 2)\n",
    "        if mirror:\n",
    "            imgdata = np.flip(imgdata, 2)\n",
    "            fptdata = np.flip(fptdata, 1)\n",
    "        # flip vertically\n",
    "        flip = np.random.randint(0, 2)\n",
    "        if flip:\n",
    "            imgdata = np.flip(imgdata, 1)\n",
    "            fptdata = np.flip(fptdata, 0)\n",
    "        # rotate by [0,1,2,3]*90 deg\n",
    "        rot = np.random.randint(0, 4)\n",
    "        if rot:\n",
    "            imgdata = np.rot90(imgdata, rot, axes=(1,2))\n",
    "            fptdata = np.rot90(fptdata, rot, axes=(0,1))\n",
    "\n",
    "        return {'idx': sample['idx'],\n",
    "                'img': imgdata.copy(),\n",
    "                'fpt': fptdata.copy(),\n",
    "                'imgfile': sample['imgfile']}\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize pixel values to the range [0, 1] measured using minmax-scaling\"\"\"\n",
    "    def __init__(self):\n",
    "        #the limits are determined according to the Dataset's nature\n",
    "\n",
    "        self.channel_min=np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6737967729568481, -605.4163208007812,\n",
    "                                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.7714285850524902, -572.1392822265625])\n",
    "        \n",
    "        self.channel_max=np.array([3560.0, 4147.0, 4780.0, 6832.0, 6143.0, 6261.0, 1.0, 1000.0,\n",
    "                                   3765.0, 4398.0, 4866.0, 6930.0, 6157.0, 6167.0, 1.0, 1000.0])\n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Returns the normalized sample\n",
    "        \n",
    "        sample: sample to be normalized\n",
    "        \n",
    "        \"\"\"\n",
    "        sample['img'] = (sample['img']-self.channel_min.reshape(\n",
    "            sample['img'].shape[0], 1, 1))/(self.channel_max.reshape(\n",
    "            sample['img'].shape[0], 1, 1)-self.channel_min.reshape(\n",
    "            sample['img'].shape[0], 1, 1))\n",
    "        return sample \n",
    "def create_dataset(*args, apply_transforms=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a dataset; uses same input parameters as PowerPlantDataset.\n",
    "    apply_transforms: if `True`, apply available transformation. Returns the data set\n",
    "    \n",
    "    \"\"\"\n",
    "    if apply_transforms:\n",
    "        data_transforms = transforms.Compose([\n",
    "            Normalize(),\n",
    "            Randomize(),\n",
    "            ToTensor()\n",
    "           ])\n",
    "    else:\n",
    "        data_transforms = None\n",
    "\n",
    "    data = firescardataset(*args, **kwargs,\n",
    "                                         transform=data_transforms)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c2e81",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd97f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a478234",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57163895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "class DoubleConv(nn.Module):\n",
    "#     \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "#     \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "#     \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        self.inc = DoubleConv(n_channels, 128)\n",
    "        self.down1 = Down(128, 256)\n",
    "        self.down2 = Down(256, 512)\n",
    "        self.down3 = Down(512, 1024)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(1024, 2048 // factor)\n",
    "        self.up1 = Up(2048, 1024 // factor, bilinear)\n",
    "        self.up2 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up3 = Up(512, 256 // factor, bilinear)\n",
    "        self.up4 = Up(256, 128, bilinear)\n",
    "        self.outc = OutConv(128, n_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = UNet(n_channels=16, n_classes=1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace38da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # start training process\n",
    "print('running on...', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666cd16",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234cebe9-2c16-482e-9038-1c16c10cf3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs, opt, loss, batch_size, ss1_t, ss2_t, ss3_t, ss4_t, ss1_v, ss2_v, ss3_v, ss4_v, mult):  \n",
    "    \"\"\"\n",
    "    Trains the model with the data. \n",
    "    \n",
    "    model (model): model instance\n",
    "    dataset (object: pandas df): dataset \n",
    "    epochs (int): number of epochs to be trained\n",
    "    opt (object): optimizer instance\n",
    "    loss (object): loss function instance\n",
    "    batch_size (int): batch size \n",
    "    ss1_t, ss2_t (int): indexes Dataset 1 for the trainig\n",
    "    ss3_t, ss4_t (int) indexes Dataset 2 for the training\n",
    "    ss1_v, ss2_v (int): indexes Dataset 1 for the validation\n",
    "    ss3_v, ss4_v (int): indexes Datset 2 for the validation\n",
    "    mult (int): times to input the data\n",
    "    \"\"\"\n",
    "    data_train = create_dataset(dataset, ss1_t, ss2_t, ss3_t, ss4_t, mult)\n",
    "    data_val = create_dataset(dataset, ss1_v, ss2_v, ss3_v, ss4_v, mult)\n",
    "    train_dl = DataLoader(data_train, batch_size, num_workers=0, pin_memory=True) #drop_last=True)\n",
    "    val_dl = DataLoader(data_val, batch_size, num_workers=0, pin_memory=True) # drop_last=True)  \n",
    "    filename=\"\"   # ending of the model filename\n",
    "    best_model={}\n",
    "    best_model[\"val_loss_total\"]=100\n",
    "    best_dc={}\n",
    "    best_dc[\"val_DC\"]=0\n",
    "    def dice2d(pred, targs):  \n",
    "        \"\"\"\n",
    "        Returns the input's Dice Coefficient metric\n",
    "\n",
    "        pred (object): Object conformed by the binary output (prediction)   \n",
    "        targs (object): Object conformed by the binary ground truth (firescar of reference)\n",
    "        \"\"\"\n",
    "        pred = pred.squeeze()\n",
    "        targs = targs.squeeze()\n",
    "        return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "    # start training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        #metrics \n",
    "        dicec_train_acc=[]\n",
    "        FN_train=[]\n",
    "        TP_train=[]\n",
    "        FP_train=[]\n",
    "#         train_acc_total=0\n",
    "        train_loss_total = 0\n",
    "        train_ious = []\n",
    "        progress = tqdm(enumerate(train_dl), desc=\"Train Loss: \",\n",
    "                        total=len(train_dl))\n",
    "        for i, batch in progress:\n",
    "            # try:\n",
    "            x = batch['img'].float().to(device)\n",
    "            y = batch['fpt'].float().to(device)\n",
    "                                                                            \n",
    "            output = model(x)\n",
    "\n",
    "            # derive binary segmentation map from prediction\n",
    "            output_binary = np.zeros(output.shape)\n",
    "            output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "            \n",
    "            # derive IoU values            \n",
    "            for j in range(y.shape[0]):                                       \n",
    "                z = jaccard_score(y[j].flatten().cpu().detach().numpy(),        \n",
    "                          output_binary[j][0].flatten())\n",
    "                if (np.sum(output_binary[j][0]) != 0 and\n",
    "                    np.sum(y[j].cpu().detach().numpy()) != 0):\n",
    "                    train_ious.append(z)\n",
    "                    TP_train.append((output_binary.squeeze()*y.cpu().detach().numpy().squeeze()).sum())\n",
    "                    FN_train.append(((output_binary.squeeze()==0) & (y.cpu().detach().numpy().squeeze()==1)).sum())\n",
    "                    FP_train.append(((output_binary.squeeze()==1) & (y.cpu().detach().numpy().squeeze()==0)).sum())\n",
    "                    dicec_train_acc.append(dice2d(output_binary,y.cpu().detach().numpy()))\n",
    "\n",
    "            # derive scalar binary labels on a per-image basis\n",
    "            y_bin = np.array(np.sum(y.cpu().detach().numpy(),\n",
    "                                    axis=(1,2)) != 0).astype(int)\n",
    "            pred_bin = np.array(np.sum(output_binary,\n",
    "                                      axis=(1,2,3)) != 0).astype(int)\n",
    "\n",
    "            # derive image-wise accuracy for this batch\n",
    "#             train_acc_total += accuracy_score(y_bin, pred_bin)\n",
    "            # derive loss                                                       \n",
    "            loss_epoch = loss(output, y.unsqueeze(dim=1))\n",
    "            train_loss_total += loss_epoch.item()\n",
    "            progress.set_description(\"Train Loss: {:.4f}\".format(\n",
    "                train_loss_total/(i+1)))\n",
    "\n",
    "            # learning\n",
    "            opt.zero_grad()\n",
    "            loss_epoch.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        # logging\n",
    "        writer.add_scalar(\"training DC\", np.average(dicec_train_acc),epoch)\n",
    "        writer.add_scalar(\"training CE\",  np.mean(FP_train)/(np.mean(TP_train)+np.mean(FP_train)), epoch)\n",
    "        writer.add_scalar(\"training OE\",  np.mean(FN_train)/(np.mean(TP_train)+np.mean(FN_train)), epoch)                         \n",
    "        writer.add_scalar(\"training loss\", train_loss_total/(i+1), epoch)\n",
    "        writer.add_scalar(\"training iou\", np.average(train_ious), epoch)\n",
    "#         writer.add_scalar(\"training acc\", train_acc_total/(i+1), epoch)\n",
    "        writer.add_scalar('learning_rate', opt.param_groups[0]['lr'], epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        val_loss_total = 0\n",
    "        val_ious = []\n",
    "#         val_acc_total = 0\n",
    "        \n",
    "        dicec_eval_acc=[]\n",
    "        FN_eval=[]\n",
    "        TP_eval=[]\n",
    "        FP_eval=[]\n",
    "        \n",
    "        progress = tqdm(enumerate(val_dl), desc=\"val Loss: \",\n",
    "                        total=len(val_dl))\n",
    "                          \n",
    "        for j, batch in progress:\n",
    "            x = batch['img'].float().to(device)\n",
    "            y = batch['fpt'].float().to(device)\n",
    "            output = model(x)\n",
    "\n",
    "          # derive loss\n",
    "            loss_epoch = loss(output, y.unsqueeze(dim=1))\n",
    "            val_loss_total += loss_epoch.item()\n",
    "\n",
    "          # derive binary segmentation map from prediction\n",
    "            output_binary = np.zeros(output.shape)\n",
    "            output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "\n",
    "          # derive IoU values\n",
    "            ious = []\n",
    "            for k in range(y.shape[0]):\n",
    "                z = jaccard_score(y[k].flatten().cpu().detach().numpy(),\n",
    "                        output_binary[k][0].flatten())\n",
    "                if (np.sum(output_binary[k][0]) != 0 and \n",
    "                    np.sum(y[k].cpu().detach().numpy()) != 0):\n",
    "                    val_ious.append(z)\n",
    "                    TP_eval.append((output_binary.squeeze()*y.cpu().detach().numpy().squeeze()).sum())\n",
    "                    FN_eval.append(((output_binary.squeeze()==0) & (y.cpu().detach().numpy().squeeze()==1)).sum())\n",
    "                    FP_eval.append(((output_binary.squeeze()==1) & (y.cpu().detach().numpy().squeeze()==0)).sum())\n",
    "                    dicec_eval_acc.append(dice2d(output_binary,y.cpu().detach().numpy()))\n",
    "                   \n",
    "          # derive scalar binary labels on a per-image basis\n",
    "            y_bin = np.array(np.sum(y.cpu().detach().numpy(),\n",
    "                                  axis=(1,2)) != 0).astype(int)\n",
    "            pred_bin = np.array(np.sum(output_binary,\n",
    "                                      axis=(1,2,3)) != 0).astype(int)\n",
    "\n",
    "          # derive image-wise accuracy for this batch\n",
    "#             val_acc_total += accuracy_score(y_bin, pred_bin)\n",
    "            \n",
    "            progress.set_description(\"val Loss: {:.4f}\".format(\n",
    "             val_loss_total/(j+1)))\n",
    "\n",
    "        # logging\n",
    "        writer.add_scalar(\"val DC\", np.average(dicec_eval_acc),epoch)\n",
    "        writer.add_scalar(\"val CE\",  np.mean(FP_eval)/(np.mean(TP_eval)+np.mean(FP_eval)), epoch)\n",
    "        writer.add_scalar(\"val OE\",  np.mean(FN_eval)/(np.mean(TP_eval)+np.mean(FN_eval)), epoch)\n",
    "        writer.add_scalar(\"val loss\", val_loss_total/(j+1), epoch)\n",
    "        writer.add_scalar(\"val iou\", np.average(val_ious), epoch)\n",
    "#         writer.add_scalar(\"val acc\", val_acc_total/(j+1), epoch)        \n",
    "        \n",
    "        print((\"Epoch {:d}: train loss={:.3f}, val loss={:.3f}, \"\n",
    "               \"train iou={:.3f}, val iou={:.3f}, \"\n",
    "                \"DC training={:.3f}, val DC={:.3f}\").format(\n",
    "                   epoch+1, train_loss_total/(i+1), val_loss_total/(j+1),\n",
    "                   np.average(train_ious), np.average(val_ious),np.average(dicec_train_acc),\n",
    "                    np.average(dicec_eval_acc)))\n",
    "\n",
    "        if (val_loss_total/(j+1))<best_model[\"val_loss_total\"]:\n",
    "            best_model[\"val_loss_total\"]=(val_loss_total/(j+1))\n",
    "            best_model[\"epoch\"]=epoch\n",
    "        if (np.average(dicec_eval_acc))>best_dc[\"val_DC\"]:\n",
    "            best_dc[\"val_DC\"]=np.average(dicec_eval_acc)\n",
    "            best_dc[\"epoch\"]=epoch\n",
    "            \n",
    "#         if epoch % 1 == 0:                                  #uncomment to save the model files\n",
    "#             torch.save(model.state_dict(),\n",
    "#             'U_Net/runs/ep{:0d}_lr{:.0e}_bs{:02d}_{:03d}_{}.model'.format(\n",
    "#                 args.ep, args.lr, args.bs, epoch, filename))\n",
    "\n",
    "        writer.flush()\n",
    "        scheduler.step(val_loss_total/(j+1))\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"best model: epoch (file): {}, val loss: {}\".format(best_model[\"epoch\"], best_model[\"val_loss_total\"]))\n",
    "    print(\"best model_dc: epoch (file): {}, val dc: {}\".format(best_dc[\"epoch\"], best_dc[\"val_DC\"]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup argument parser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f')\n",
    "\n",
    "parser.add_argument('-ep', type=int, default=25,    \n",
    "                    help='Number of epochs')\n",
    "parser.add_argument('-bs', type=int, nargs='?',             \n",
    "                    default=16, help='Batch size')\n",
    "parser.add_argument('-lr', type=float,\n",
    "                    nargs='?', default=0.0001, help='Learning rate')\n",
    "# parser.add_argument('-mo', type=float,\n",
    "#                     nargs='?', default=0.7, help='Momentum')    #for SGD optimizer\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# setup tensorboard writer\n",
    "writer = SummaryWriter('U_Net/runs/'+\"ep{:0d}_lr{:.0e}_bs{:03d}/\".format(\n",
    "    args.ep, args.lr, args.bs))\n",
    "\n",
    "# initialize loss function\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# initialize optimizer\n",
    "# opt = optim.SGD(model.parameters(), lr=args.lr, momentum=args.mo)\n",
    "opt = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# initialize scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min',\n",
    "                                                 factor=0.5, threshold=1e-4,\n",
    "                                                 min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353adc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Runs training\n",
    "# model.load_state_dict(torch.load(  #if it is desired to start the training from a model\n",
    "#  \"Path/filename\" , map_location=torch.device('cpu'))) \n",
    "train_model(model, args.ep, opt, loss, args.bs)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c5fc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b1502-7b75-4ca5-bef8-9f11871b838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads a model of a specific epoch to evaluate\n",
    "# model.load_state_dict(torch.load(\n",
    "#     \"path/filename\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evald1=pd.read_csv(\"path/Dataset1/evaluation\")\n",
    "# evald2=pd.read_csv(\"path/Dataset2/evaluation\") \n",
    "# evald=pd.concat([evald1,evald2],axis=0,ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ab902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "np.random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "def evaluationevaluation(dataset, subset_size1, subset_size2, subset_size3, subset_size4, mult):\n",
    "    \"\"\"\n",
    "    Evaluates the metrics of the given dataset and plots images for each input comparing the pre and post-fire images and\n",
    "    the original firescar vs the model's prediction.\n",
    "    \n",
    "    dataset (object):  Pandas dataframe with the data's filenames from two different regions. There are 3 columns with the required data filenames for \n",
    "    each input. \"ImPosF\": The image post Fire, \"ImgPreF\": The image pre Fire, and \"FireScar_tif\": The label, in a raster file\n",
    "    subset_size1 (int): index of the first input from the Dataset 1: Region of Valparaiso\n",
    "    subset_size2 (int): index of the last input from the Dataset 1: Region of Valparaiso\n",
    "    subset_size3 (int): index of the first input from the Dataset 2: Region of Biobio\n",
    "    subset_size4 (int): index of the last input from the Dataset 2: Region of Biobio\n",
    "    mult (int): times to input the data\n",
    "    transform: in case there is an aditional transformation to apply to the data, it must be given\n",
    "\n",
    "    \"\"\"\n",
    "    data_val = create_dataset(dataset, subset_size1, subset_size2, subset_size3, subset_size4, mult)\n",
    "\n",
    "    batch_size = 1 # 1 to create diagnostic images, any value otherwise\n",
    "    all_dl = DataLoader(data_val, batch_size=batch_size)#, shuffle=True)\n",
    "    progress = tqdm(enumerate(all_dl), total=len(all_dl))\n",
    "\n",
    "    dicec_eval_acc=[]\n",
    "    FN_eval=[]\n",
    "    TP_eval=[]\n",
    "    FP_eval=[]\n",
    "    comission=[]\n",
    "    omission=[]\n",
    "    cont=0\n",
    "    model.eval()\n",
    "    \n",
    "    def dice2d(pred, targs):  \n",
    "        \"\"\"\n",
    "        Returns the input's Dice Coefficient metric\n",
    "\n",
    "        pred (object): Object conformed by the binary output (prediction)   \n",
    "        targs (object): Object conformed by the binary ground truth (firescar of reference)\n",
    "        \"\"\"\n",
    "        pred = pred.squeeze()\n",
    "        targs = targs.squeeze()\n",
    "        return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "    # define loss function\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # run through test data\n",
    "    all_ious = []\n",
    "    # all_accs = []\n",
    "    test_df=pd.DataFrame(columns=[\"ImgPosF\",\"iou\",\"DC\",\"CE\",\"OE\"])\n",
    "    for i, batch in progress:\n",
    "        x, y = batch['img'].float().to(device), batch['fpt'].float().to(device)\n",
    "        idx = batch['idx']\n",
    "\n",
    "        output = model(x).cpu()\n",
    "\n",
    "        # obtain binary prediction map\n",
    "        pred = np.zeros(output.shape)\n",
    "        pred[output >= 0] = 1\n",
    "\n",
    "        # derive Iou score\n",
    "        cropped_iou = []\n",
    "        for j in range(y.shape[0]):\n",
    "            z = jaccard_score(y[j].flatten().cpu().detach().numpy(),\n",
    "                              pred[j][0].flatten())\n",
    "            if (np.sum(pred[j][0]) != 0 and\n",
    "                np.sum(y[j].cpu().detach().numpy()) != 0):\n",
    "                cropped_iou.append(z)       \n",
    "\n",
    "        all_ious = [*all_ious, *cropped_iou]\n",
    "\n",
    "        # derive scalar binary labels on a per-image basis\n",
    "        y_bin = np.array(np.sum(y.cpu().detach().numpy(),\n",
    "                                axis=(1,2)) != 0).astype(int)\n",
    "        prediction = np.array(np.sum(pred,\n",
    "                                   axis=(1,2,3)) != 0).astype(int)\n",
    "        # derive image-wise accuracy for this batch\n",
    "    #     all_accs.append(accuracy_score(y_bin, prediction))\n",
    "\n",
    "        # derive binary segmentation map from prediction\n",
    "        output_binary = np.zeros(output.shape)\n",
    "        output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "\n",
    "        if batch_size == 1:\n",
    "\n",
    "            if prediction == 1 and y_bin == 1:\n",
    "                res = 'true_pos'\n",
    "            elif prediction == 0 and y_bin == 0:\n",
    "                res = 'true_neg'\n",
    "            elif prediction == 0 and y_bin == 1:\n",
    "                res = 'false_neg'\n",
    "            elif prediction == 1 and y_bin == 0:\n",
    "                res = 'false_pos'    \n",
    "            #scores fix\n",
    "            TP_eval.append((output_binary.squeeze()*y.cpu().detach().numpy().squeeze()).sum())\n",
    "            FN_eval.append(((output_binary.squeeze()==0) & (y.cpu().detach().numpy().squeeze()==1)).sum())\n",
    "            FP_eval.append(((output_binary.squeeze()==1) & (y.cpu().detach().numpy().squeeze()==0)).sum())\n",
    "            dicec_eval_acc.append(dice2d(output_binary,y.cpu().detach().numpy()))\n",
    "            test_df.loc[cont,\"OE\"]=FN_eval[cont]/(TP_eval[cont]+FN_eval[cont])\n",
    "            test_df.loc[cont,\"CE\"]=FP_eval[cont]/(TP_eval[cont]+FP_eval[cont])\n",
    "            test_df.loc[cont,\"DC\"]=dice2d(output_binary,y.cpu().detach().numpy()) \n",
    "            test_df.loc[cont,\"ImgPosF\"]=(batch['imgfile'][0].split(\"/\")[2])\n",
    "            OE=FN_eval[cont]/(TP_eval[cont]+FN_eval[cont])\n",
    "            this_iou = jaccard_score(y[0].flatten().cpu().detach().numpy(),\n",
    "                                     pred[0][0].flatten())\n",
    "            test_df.loc[i,\"iou\"]=this_iou        \n",
    "\n",
    "\n",
    "             # create plot\n",
    "            f, (ax1, ax2, ax3,ax4) = plt.subplots(1, 4, figsize=(20,20))\n",
    "            x=x.cpu()\n",
    "            y=y.cpu()\n",
    "\n",
    "            # false color plot Image prefire\n",
    "            ax1.imshow(0.2+1.5*(np.dstack([x[0][12], x[0][11], x[0][10]])-np.min([x[0][12].numpy(),\n",
    "                                x[0][11].numpy(), x[0][10].numpy()]))/(np.max([x[0][12].numpy(),\n",
    "                                x[0][11].numpy(), x[0][10].numpy()])-np.min([x[0][12].numpy(),\n",
    "                                x[0][11].numpy(), x[0][10].numpy()])), origin='upper')\n",
    "\n",
    "            ax1.set_title(\"ImgPreF\",fontsize=12)\n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "            #Image Pos-Fire\n",
    "            ax2.imshow(0.2+1.5*(np.dstack([x[0][4], x[0][3], x[0][2]])-np.min([x[0][4].numpy(), \n",
    "                                x[0][3].numpy(), x[0][2].numpy()]))/(np.max([x[0][4].numpy(),\n",
    "                                x[0][3].numpy(), x[0][2].numpy()])-np.min([x[0][4].numpy(),\n",
    "                                x[0][3].numpy(), x[0][2].numpy()])), origin='upper')\n",
    "\n",
    "            ax2.set_title(\"ImgPosF\",fontsize=12)\n",
    "            ax2.set_xticks([])\n",
    "            ax2.set_yticks([])\n",
    "\n",
    "            # segmentation ground-truth and prediction\n",
    "            ax3.imshow(y[0], cmap='Greys_r', alpha=1)\n",
    "            ax4.imshow(pred[0][0], cmap='Greys_r', alpha=1)\n",
    "            ax3.set_title(\"Original Scar\",fontsize=12)\n",
    "            ax3.set_xticks([])\n",
    "            ax3.set_yticks([])\n",
    "            ax3.annotate(\"IoU={:.2f}\".format(this_iou), xy=(5,15), fontsize=15)\n",
    "\n",
    "            ax4.set_title({'true_pos': 'Scar Prediction: True Positive \\n  -IoU={:.2f},' \n",
    "                           '-OE={:.2f}, -CE={:.2f}, -DC={:.2F}'.format(this_iou, test_df.loc[cont,\"OE\"],test_df.loc[cont,\"CE\"],test_df.loc[cont,\"DC\"]),\n",
    "                   'true_neg': 'Scar Prediction: True Negative \\n  -IoU={:.2f},' \n",
    "                '-OE={:.2f}, -CE={:.2f}, -DC={:.2F}'.format(this_iou,test_df.loc[cont,\"OE\"],test_df.loc[cont,\"CE\"],test_df.loc[cont,\"DC\"]),\n",
    "                   'false_pos': 'Scar Prediction: False Positive   -IoU={:.2f},'\n",
    "                 '-OE={:.2f}, -CE={:.2f}, -DC={:.2F}'.format(this_iou, test_df.loc[cont,\"OE\"],test_df.loc[cont,\"CE\"],test_df.loc[cont,\"DC\"]),\n",
    "                    'false_neg': 'Scar Prediction: False Negative \\n  -IoU={:.2f},'\n",
    "                '-OE={:.2f}, -CE={:.2f}, -DC={:.2F}'.format(this_iou,test_df.loc[cont,\"OE\"], 0,test_df.loc[cont,\"DC\"])}[res],\n",
    "                          fontsize=12)\n",
    "\n",
    "            cont+=1      \n",
    "\n",
    "            f.subplots_adjust(0.05, 0.02, 0.95, 0.9, 0.05, 0.05)\n",
    "\n",
    "            # plt.savefig(\"U_Net/output/\"+(os.path.split(batch['imgfile'][0])[1]).\\\n",
    "            #             replace('.tif', '.png').replace(':', '_'),\n",
    "            #              dpi=200)   \n",
    "\n",
    "            plt.close()     #comment to display\n",
    "\n",
    "    print('iou:', len(all_ious), np.average(all_ious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c60802-dfa5-4f53-a6dd-358ccedd8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(dataset, subset_size1, subset_size2, subset_size3, subset_size4, mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06b17c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Test analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651577eb-cc2a-4238-8e34-d7e0272dd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv(\"U_Net/runs/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d48e16-e5e8-491a-9837-d80dde55bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"DC\"].mean(), test_df[\"OE\"].mean(),test_df[\"CE\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
